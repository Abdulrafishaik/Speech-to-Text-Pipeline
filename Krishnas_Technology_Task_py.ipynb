{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NXEdjIra11I",
        "outputId": "11f33529-df00-4220-eb37-8ec97006881a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/800.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement pypdub (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pypdub\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper --quiet\n",
        "!pip install streamlit --quiet\n",
        "!pip install pypdub --quiet\n",
        "!pip install ffmpeg-python --quiet\n",
        "!pip install torch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soundfile --quiet"
      ],
      "metadata": {
        "id": "jhwMhYhaeVZr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H1k5C2hhUUc",
        "outputId": "058feebf-62ba-49e1-8e64-c022b1366b68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "olvYLZt6e7kx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=whisper.load_model(\"base\")\n",
        "audio_file=model.transcribe(\"/content/ai_audio.mp3\")\n",
        "print(audio_file['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diHRM9Gce8J-",
        "outputId": "4b96a303-e5ec-4cef-d9eb-bbeb1bf1afc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 81.1MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Artificial intelligence, often abbreviated as AI, refers to the simulation of human intelligence by machines. It enables computers and systems to perform tasks such as learning, reasoning, problem solving, and language understanding. Today, AI powers technologies like voice assistance, recommendation engines, chatbots, self-driving cars, and more. Machine learning, a subset of AI, allows systems to improve automatically through experience. While AI offers great promise in fields like healthcare, finance, and education, it also raises important questions about ethics, data privacy, and job automation. As AI continues to evolve, it's crucial that we develop and deploy it responsibly to benefit humanity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for segment in audio_file[\"segments\"]:\n",
        "    print(f\"[{segment['start']:.2f} - {segment['end']:.2f}] {segment['text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-czuGbyAiqtj",
        "outputId": "4eeec67f-3cc7-4052-8b72-e6b15790bcaa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00 - 9.00]  Artificial intelligence, often abbreviated as AI, refers to the simulation of human intelligence by machines.\n",
            "[9.00 - 18.20]  It enables computers and systems to perform tasks such as learning, reasoning, problem solving, and language understanding.\n",
            "[18.20 - 27.80]  Today, AI powers technologies like voice assistance, recommendation engines, chatbots, self-driving cars,\n",
            "[27.80 - 36.30]  and more. Machine learning, a subset of AI, allows systems to improve automatically through experience.\n",
            "[36.30 - 49.40]  While AI offers great promise in fields like healthcare, finance, and education, it also raises important questions about ethics, data privacy, and job automation.\n",
            "[49.40 - 57.40]  As AI continues to evolve, it's crucial that we develop and deploy it responsibly to benefit humanity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install noisereduce --quiet"
      ],
      "metadata": {
        "id": "F6Ne8cTHj9Ak"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import noisereduce as nr\n",
        "import soundfile as sf"
      ],
      "metadata": {
        "id": "7SEb2hYVkO5m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, rate=sf.read(\"/content/ai_audio.mp3\")\n",
        "reduce_noise=nr.reduce_noise(y=data,sr=rate)"
      ],
      "metadata": {
        "id": "z8UL0JUZkmeH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sf.write(\"cleaned_audio.wav\", reduce_noise, rate)"
      ],
      "metadata": {
        "id": "8r1TwJqdlyPD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask_ngrok --quiet"
      ],
      "metadata": {
        "id": "OBczHF5vgDhk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flask pyngrok openai-whisper noisereduce soundfile librosa\n"
      ],
      "metadata": {
        "id": "NAi0vH39gnIh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "import threading\n",
        "import tempfile\n",
        "import os\n",
        "import whisper\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import noisereduce as nr\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Set ngrok auth token\n",
        "ngrok.set_auth_token(\"2xglfrOOwfqYTSWdzUdwjrHHAeh_6Ug9uQKqdMjrfQEvfpdEL\")\n",
        "\n",
        "# Flask app setup\n",
        "app = Flask(__name__)\n",
        "\n",
        "HTML = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Whisper Transcription</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h2>Upload Audio File</h2>\n",
        "    <form method=\"post\" enctype=\"multipart/form-data\">\n",
        "        <input type=\"file\" name=\"audio_file\" accept=\"audio/*\" required><br><br>\n",
        "        <label><input type=\"checkbox\" name=\"noise_reduce\"> Apply Noise Reduction</label><br><br>\n",
        "        <input type=\"submit\" value=\"Transcribe\">\n",
        "    </form>\n",
        "\n",
        "    {% if transcript %}\n",
        "    <h3>Transcript:</h3>\n",
        "    <p>{{ transcript }}</p>\n",
        "    <h4>Segments:</h4>\n",
        "    <ul>\n",
        "        {% for segment in segments %}\n",
        "        <li><strong>[{{ segment.start | round(2) }} - {{ segment.end | round(2) }}]</strong>: {{ segment.text }}</li>\n",
        "        {% endfor %}\n",
        "    </ul>\n",
        "    {% endif %}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    transcript = None\n",
        "    segments = []\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "        file = request.files[\"audio_file\"]\n",
        "        reduce_noise = 'noise_reduce' in request.form\n",
        "\n",
        "        y, sr = librosa.load(file, sr=None)\n",
        "        if reduce_noise:\n",
        "            y = nr.reduce_noise(y=y, sr=sr)\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp:\n",
        "            sf.write(temp.name, y, sr)\n",
        "            audio_path = temp.name\n",
        "\n",
        "        result = model.transcribe(audio_path)\n",
        "        transcript = result[\"text\"]\n",
        "        segments = result[\"segments\"]\n",
        "\n",
        "        os.remove(audio_path)\n",
        "\n",
        "    return render_template_string(HTML, transcript=transcript, segments=segments)\n",
        "\n",
        "# Start Flask in thread\n",
        "def run_flask():\n",
        "    app.run(port=7860)\n",
        "\n",
        "thread = threading.Thread(target=run_flask)\n",
        "thread.start()\n",
        "\n",
        "# Connect ngrok to port 7860\n",
        "public_url = ngrok.connect(7860)\n",
        "print(\"Your app is live at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1l3NDe6h-5X",
        "outputId": "db043c47-8c15-4553-ff3c-04bdf82fbb51"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:7860\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your app is live at: NgrokTunnel: \"https://518f-34-58-56-237.ngrok-free.app\" -> \"http://localhost:7860\"\n"
          ]
        }
      ]
    }
  ]
}